# This script is a rough prototype for the running pymagicc within REMIND

# Most of the code here should actually be in a function or class, this is just a prototype
# Variables that in principle should be set as arguments (to be provided in the REMIND call)
# or configuration flags (to be set in a default configuration file and modified later) are
# marked with a #FIXME comment.

#%%

import os
# These are here to ensure numpy and others don't spawn nproc threads on the login nodes at import
# if running interactively. # TODO: Set these to SLURM environment variables if called from there
os.environ["OMP_NUM_THREADS"] = "1" 
os.environ["OPENBLAS_NUM_THREADS"] = "1" 
os.environ["MKL_NUM_THREADS"] = "1" 
os.environ["VECLIB_MAXIMUM_THREADS"] = "1" 
os.environ["NUMEXPR_NUM_THREADS"] = "1" 

import shutil
import sys
import re
import logging #TODO: Implement debug logs if script called with an argument

import numpy as np
import yaml
import pymagicc
import f90nml
import pyreadr

# Import the GAMS API
# #TODO: Use low-level GDX libraries (gdxcc and its python wrapper)
# instead of calling the GAMS API like done here.
# The API is in a folder like '/p/system/packages/gams/35.1.0/apifiles/Python/api_39'
gams_root = os.path.dirname(shutil.which("gams"))
gamsapi_path = os.path.join(gams_root,"apifiles","Python","api_" + str(sys.version_info[0]) + str(sys.version_info[1]))
sys.path.append(gamsapi_path)
sys.path.append(os.path.dirname(gamsapi_path) + "/gams")
from gams import *

# Import other files after the GAMS API is in place
from gdxutils import *

#%%
# with open(cfgpath, "r") as ymlfile:
    # cfg = yaml.safe_load(ymlfile)

#%%
# ============================ CONFIGURATION/ARGUMENTS ==============================

# Full path to the REMIND run. Obtained as the calling working directory
run_path = os.path.join(os.getcwd() + "/")
# TESTING override path
# run_path = '/p/projects/piam/abrahao/piam-scm-interface/testOneRegi'

# Path to the configuration YAML file in the run's path
cfg_path = os.path.join(run_path, "cfg.txt")

# Read the run's configuration file. This allows configuration variables here be dependent
# on flags set in REMIND's cfg. 
# #TODO: set everything on REMIND trough this, this script just adapts to cfg
with open(cfg_path, "r") as ymlfile:
    cfg = yaml.safe_load(ymlfile)

# Name of the .SCEN MAGICC scenario file to run
# #FIXME argument. This probably should be provided by the REMIND cfg later
# #TODO this is generated by REMIND/core/magicc.gms assuming defaults that could not 
# be compatible with other versions of MAGICC going forward. We should eventually
# replace that with something more generic, such as calling a script/method here on the interface
# that reads fulldata.gdx and handles compatibility
# fname_emiscen = run_path + 'magicc/REMIND_testOneRegi.SCEN'
fname_emiscen = os.path.join(run_path ,'magicc/REMIND_' + cfg["title"] + '.SCEN')

# Name of the output file containing a Dataframe of all MAGICC/SCM output
fname_output = os.path.join(run_path ,'scm_output')

# MAGICC6 binary location. 
# #FIXME configuraion. This could be set from cfg["magicc_template"], but the version used by
# pymagicc currently needs some tweaks as described below.
# Since we don't have the MAGICC source code, this has to mimick the version
# expected by pymagicc. That means being in a /run subfolder and write output 
# to a /out subfolder
# This shell script does the job using PIKs in-house binaries 
# while we don't have source access
magicc6_binary = '/p/projects/piam/abrahao/magicc6/run/run_magicc6.sh'
# magicc6_binary = '/p/projects/piam/abrahao/magicc6/run/magicc6'
magicc6_run_path = os.path.dirname(magicc6_binary)

# Extra tuning files containing additional parameters
# These are .CFG files in magicc6_run_path,
# which are FORTRAN namelists. If there are repeated parameters
# they are overwritten in the list's order (i.e. the one in the last file is kept)
# Keep in mind that MAGICC still reads its default namelists before reading these,
# so there are configurations that are not set here and may be version-dependent
# Cant't know which ones w/o code, but pymagicc's documentation suggests 
# DEFAULTALL_XX (not sure which) and USER. YEARS is also read at some point.
# 
# WARNING FIXME: No combination tried yet leads to *exactly* the same values as 
# a manual run (backwards compatible), but differences are of 10e-2 order in temperature (K) and RF (W/m2).
# The difference is likely in the order which PYMAGICC, USER and DEFAULTALL parameters are read.
# 
# We could set these in REMIND's cfg in the future
# GaA: These are the ones used by default by PIKs MAGICC, with C4MIP-calibrated 
# carbon cycle parameters and CMIP3-calibrated core climate parameters
tuning_extra = [
    # "MAGCFG_DEFAULTALL_62",
    # "MAGCFG_USER",
    "MAGTUNE_C4MIP_BERN",
    "MAGTUNE_FULLTUNE_MEDIUM_CMIP3_ECS3"
    ]


## %%
# ============================ PRERUN ==============================

# emiscen = pymagicc.io.MAGICCData(fname_emiscen)

# Set the environment variable for pymagicc
if "MAGICC_EXECUTABLE_6" not in os.environ:
    os.environ["MAGICC_EXECUTABLE_6"] = magicc6_binary

# Load the scenario file from REMIND
# Due to a bug(ish) in pymagicc, this only works with REMIND-generated files after
# the changes in this PR, made after v2.1.1: https://github.com/openscm/pymagicc/pull/328
emiscen = pymagicc.io.MAGICCData(fname_emiscen)

# Read and combine the namelist parameters from the extra tuning files
tuning_params = f90nml.Namelist()
tuning_fnames = [os.path.join(magicc6_run_path,name+".CFG") for name in tuning_extra]

for tuning_fname in tuning_fnames:
    nml = f90nml.read(tuning_fname)
    tuning_params.patch(nml)

## %%
# ============================ RUN ==============================

# Currently this is using pymagicc directly instead of the openscm-runner wrapper
# TODO: Convert to openscm-runner and set up a cfg to decide between MAGICC6, MAGICC7 or FAIR

# extra_params = {}
extra_params = tuning_params['nml_allcfgs'].todict()
# extra_params = {
#     "FILE_TUNINGMODEL" :  "C4MIP_BERN",
#     "FILE_TUNINGMODEL_2" :  "FULLTUNE_MEDIUM_CMIP3_ECS3",
# }

# This creates a temporary copy of MAGICC (when instantiating pymagicc.MAGICC6), 
# runs it and collects all results in an scmdata.ScmRun object
# Repeated runs with the same instance of MAGICC6 should be faster (no copying), and this should allow
# parallel computing using multiprocessing for e.g. TIRF, statistical runs
# #TODO: Calling it without arguments uses the default configuration, parameters and initial conditions
# set in the files in the binary's folder (i.e. same config as REMIND's MAGICC). These can all be changed here. 
# Ideally, this part would point to default files and/or configuration flags set in this folder and be
# completely independent of the files in the binary's folder. 
# #FIXME: This is taking 4.31s vs. 0.58s in pymagicc's Example notebook. Might have to do with our unfit binaries.
# #FIXME: Set up non loading of monthly data to squash warnings

with pymagicc.MAGICC6() as model:
    results = model.run(
        emiscen,
        **extra_params
        )

# %%
# ============================ POSTRUN ==============================
# This part will send information back to GAMS via GDX files
# Functions defined in gdxutils.py. Currently uses the full GAMS API

# Write GDXs
# Write surface temperature
write_gdx_parameter_from_results("Surface Temperature", "pm_globalMeanTemperature", results, "tall", os.path.join(run_path,"p15_magicc_temp.gdx"), region = "World")

# Write anthropogenic radiative forcing
write_gdx_parameter_from_results("Radiative Forcing|Anthropogenic","p15_forc_magicc", results, "tall", os.path.join(run_path,"p15_forc_magicc.gdx"), region = "World")

#%%
# ============================ REPORTING ==============================
# FULL OUTPUT FORMAT POSSIBILITIES
# There are a bunch of standards and formats we could just choose from to output the full results data structure,
# or manipulate them with pandas to create one that suits us. This file would in principle be put in 
# the REMIND run folder and used just for reporting, all the communication should be done before this step 
# and just with selected variables. So we probably want a standard that will leave the least work
# to the reporting libraries. 
# 
# Keep in mind that the region definitions here are the MAGICC boxes and agreggations (N and S hemispheres,
# ocean and land) not REMIND or R5 regions as in the scenario file/object
# 
# The examples here are all in CSV for now but RDS would probably be best for interfacing with 
# remind reporting (and faster). RDS and GDX are possible with new dependencies and a bit of work,
# the current RDS solution is a bit too slow (>20s)

# This outputs a CSV with a wide dataframe (dates as columns) with openscm standards
# results.to_csv("output_test_to_csv.csv")

# Converting to a xarray.Dataarray first yields a long dataframe (dates as rows) with openscm standards
# results.to_xarray().to_dataframe().to_csv("output_test_xarray_to_csv.csv")

# The pyam module can also be used to get the data with IAMC standards. The default writes to a wide format
# results.to_iamdataframe().to_csv("output_test_iamdataframe.csv")

# Converting the IAMC dataframe to a pandas dataframe automatically converts to long (dates as rows)
# results.to_iamdataframe().as_pandas().to_csv("output_test_iamdatafram_pandas.csv")

# There is a helper function to convert dates to years too. This gets an IAMC standard long df (years as rows)
# results.to_iamdataframe().swap_time_for_year().as_pandas().to_csv("output_test_iamdatafram_pandas_years.csv")

df_out = results.to_iamdataframe().swap_time_for_year().as_pandas()

# Writing to CSV is a bit slow. Using pyreadr to write to RDS is absurdly slow at the moment, probably
# could be much faster if we get rid of this row for-loop upstream: https://github.com/ofajardo/pyreadr/blob/master/pyreadr/_pyreadr_writer.py#L228
df_out.to_csv(fname_output+".csv", index = False)
# pyreadr.write_rds(fname_output+".rds", df_out) 

# %%
# A bunch of filters/plots left here to debug for now
# results.filter(variable = "Emis*CO2", region="World").line_plot(hue="variable")
# results.filter(variable="Atmos*Conc*CO2", region="World").line_plot(hue="variable")
# results.filter(variable = "Radiative Forcing").line_plot(hue="region")
# results.filter(variable="Surface Temperature").line_plot(hue="region")

# results.metadata['parameters']['allcfgs']['co2_detrituspool_initial']
# results.filter(region = "World", variable = ["*Radiative Forcing","Surface Temperature"]).timeseries(time_axis="year")[2100]
# results.filter(region = "World", variable = "BIOMASSAER_SRF").line_plot()

# results.filter(region="World", variable='Radiative Forcing|Anthropogenic').to_iamdataframe().swap_time_for_year().as_pandas()
# results.filter(region="World", variable='Surface Temperature').to_iamdataframe().swap_time_for_year().as_pandas()
